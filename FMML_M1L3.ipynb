{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagavamsik/Vamsikrishna_labs_projects/blob/main/FMML_M1L3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3yfry25JgZK"
      },
      "source": [
        "# Data Augmentation\n",
        "\n",
        "FMML Module 1, Lab 3\n",
        "\n",
        "In this lab, we will see how augmentation of data samples help in improving the machine learning performance. Augmentation is the process of creating new data samples by making reasonable modifications to the original data samples. This is particularly useful when the size of the training data is small. We will use the MNISt dataset for this lab. We will also reuse functions from the previous labs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZU8_elooqP0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from sklearn.utils.extmath import cartesian\n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "\n",
        "rng = np.random.default_rng(seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJvmWJ58ovx5"
      },
      "outputs": [],
      "source": [
        "# loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "\n",
        "# normalizing the data\n",
        "train_X = train_X / 255\n",
        "test_X = test_X / 255\n",
        "\n",
        "# subsample from images and labels. Otherwise it will take too long!\n",
        "train_X = train_X[::1200, :, :].copy()\n",
        "train_y = train_y[::1200].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XamH6z1Rt7S"
      },
      "source": [
        "Let us borrow a few functions from the previous labs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk2W5_3BRLMS"
      },
      "outputs": [],
      "source": [
        "def NN1(traindata, trainlabel, query):\n",
        "    \"\"\"\n",
        "    This function takes in the training data, training labels and a query point\n",
        "    and returns the predicted label for the query point using the nearest neighbour algorithm\n",
        "\n",
        "    traindata: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    trainlabel: numpy array of shape (n,) where n is the number of samples\n",
        "    query: numpy array of shape (d,) where d is the number of features\n",
        "\n",
        "    returns: the predicted label for the query point which is the label of the training data which is closest to the query point\n",
        "    \"\"\"\n",
        "    diff = (\n",
        "        traindata - query\n",
        "    )  # find the difference between features. Numpy automatically takes care of the size here\n",
        "    sq = diff * diff  # square the differences\n",
        "    dist = sq.sum(1)  # add up the squares\n",
        "    label = trainlabel[np.argmin(dist)]\n",
        "    return label\n",
        "\n",
        "\n",
        "def NN(traindata, trainlabel, testdata):\n",
        "    \"\"\"\n",
        "    This function takes in the training data, training labels and test data\n",
        "    and returns the predicted labels for the test data using the nearest neighbour algorithm\n",
        "\n",
        "    traindata: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    trainlabel: numpy array of shape (n,) where n is the number of samples\n",
        "    testdata: numpy array of shape (m,d) where m is the number of test samples and d is the number of features\n",
        "\n",
        "    returns: the predicted labels for the test data which is the label of the training data which is closest to each test point\n",
        "    \"\"\"\n",
        "    traindata = traindata.reshape(-1, 28*28)\n",
        "    testdata = testdata.reshape(-1, 28*28)\n",
        "    predlabel = np.array([NN1(traindata, trainlabel, i) for i in testdata])\n",
        "    return predlabel\n",
        "\n",
        "\n",
        "def Accuracy(gtlabel, predlabel):\n",
        "    \"\"\"\n",
        "    This function takes in the ground-truth labels and predicted labels\n",
        "    and returns the accuracy of the classifier\n",
        "\n",
        "    gtlabel: numpy array of shape (n,) where n is the number of samples\n",
        "    predlabel: numpy array of shape (n,) where n is the number of samples\n",
        "\n",
        "    returns: the accuracy of the classifier which is the number of correct predictions divided by the total number of predictions\n",
        "    \"\"\"\n",
        "    assert len(gtlabel) == len(\n",
        "        predlabel\n",
        "    ), \"Length of the ground-truth labels and predicted labels should be the same\"\n",
        "    correct = (\n",
        "        gtlabel == predlabel\n",
        "    ).sum()  # count the number of times the groundtruth label is equal to the predicted label.\n",
        "    return correct / len(gtlabel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGiA3LmDSJZo"
      },
      "source": [
        "In this lab, we will use the image pixels themselves as features, instead of extracting features. Each image has 28*28 pixels, so we will flatten them to 784 pixels to use as features. Note that this is very compute intensive and will take a long time. Let us first check the baseline accuracy on the test set without any augmentations. We hope that adding augmentations will help us to get better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tQvnoasRNEV"
      },
      "outputs": [],
      "source": [
        "testpred = NN(train_X, train_y, test_X)\n",
        "print(\"Baseline accuracy without augmentation:\",\n",
        "      Accuracy(test_y, testpred)*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfkcMfhIZQ7U"
      },
      "source": [
        "Let us try to improve this accuracy using augmentations. When we create augmentations, we have to make sure that the changes reflect what will naturally occur in the dataset. For example, we should not add colour to our samples as an augmentation because they do not naturally occur. We should not also flip the images in MNIST, because flipped images have different meanings for digits. So, we will use the following augmentations:\n",
        "\n",
        "### Augmentation 1: Rotation\n",
        "\n",
        "Let us try rotating the image a little. We will use the `rotate` function from the `skimage` module. We will rotate the image by 10 degrees and -10 degrees. Rotation is a reasonable augmentation because the digit will still be recognizable even after rotation and is representative of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5WolJ9fZE7L"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axs[0].imshow(train_X[2], cmap=\"gray\")\n",
        "axs[0].set_title(\"Original Image\")\n",
        "\n",
        "axs[1].imshow(rotate(train_X[2], 10), cmap=\"gray\")\n",
        "axs[1].set_title(\"Rotate +10 degrees\")\n",
        "\n",
        "axs[2].imshow(rotate(train_X[2], -10), cmap=\"gray\")\n",
        "axs[2].set_title(\"Rotate -10 degrees\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE33Yxgggu0c"
      },
      "source": [
        "After rotating, the the class of the image is still the same. Let us make a function to rotate multiple images by random angles. We want a slightly different image every time we run this function. So, we generate a random number between 0 and 1 and change it so that it lies between -constraint/2 and +constraint/2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyM7pUV7Reze"
      },
      "outputs": [],
      "source": [
        "def augRotate(sample, angleconstraint):\n",
        "    \"\"\"\n",
        "    This function takes in a sample and an angle constraint and returns the augmented sample\n",
        "    by rotating the sample by a random angle within the angle constraint\n",
        "\n",
        "    sample: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    angleconstraint: the maximum angle by which the sample can be rotated\n",
        "\n",
        "    returns: the augmented sample which is the input sample rotated by a random angle within the angle constraint\n",
        "    \"\"\"\n",
        "    if angleconstraint == 0:\n",
        "        return sample\n",
        "    if len(sample.shape) == 2:\n",
        "        # make sure the sample is 3 dimensional\n",
        "        sample = np.expand_dims(sample, 0)\n",
        "    angle = rng.random(len(sample))  # generate random numbers for angles\n",
        "    # make the random angle constrained\n",
        "    angle = (angle - 0.5) * angleconstraint\n",
        "    nsample = sample.copy()  # preallocate the augmented array to make it faster\n",
        "    for ii in range(len(sample)):\n",
        "        nsample[ii] = rotate(sample[ii], angle[ii])\n",
        "    return np.squeeze(nsample)  # take care if the input had only one sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDk-N5VNjar9"
      },
      "source": [
        "This function returns a slightly different image each time we call it. So we can increase the number of images in the sample by any multiple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw3O9zGFgI8K"
      },
      "outputs": [],
      "source": [
        "sample = train_X[20]\n",
        "angleconstraint = 70\n",
        "\n",
        "fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
        "\n",
        "axs[0].imshow(sample, cmap=\"gray\")\n",
        "axs[0].set_title(\"Original Image\")\n",
        "\n",
        "axs[1].imshow(augRotate(sample, angleconstraint), cmap=\"gray\")\n",
        "axs[1].set_title(\"Aug. Sample 1\")\n",
        "\n",
        "axs[2].imshow(augRotate(sample, angleconstraint), cmap=\"gray\")\n",
        "axs[2].set_title(\"Aug. Sample 2\")\n",
        "\n",
        "axs[3].imshow(augRotate(sample, angleconstraint), cmap=\"gray\")\n",
        "axs[3].set_title(\"Aug. Sample 3\")\n",
        "\n",
        "axs[4].imshow(augRotate(sample, angleconstraint), cmap=\"gray\")\n",
        "axs[4].set_title(\"Aug. Sample 4\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytv3NxF-kgxN"
      },
      "source": [
        "Let us augment the whole dataset and see if this improves the test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNzNAoDBkRzj"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "angleconstraint = 60\n",
        "naugmentations = 5\n",
        "\n",
        "# augment\n",
        "augdata = train_X  # we include the original images also in the augmented dataset\n",
        "auglabel = train_y\n",
        "for ii in range(naugmentations):\n",
        "    augdata = np.concatenate(\n",
        "        (augdata, augRotate(train_X, angleconstraint))\n",
        "    )  # concatenate the augmented data to the set\n",
        "    auglabel = np.concatenate(\n",
        "        (auglabel, train_y)\n",
        "    )  # the labels don't change when we augment\n",
        "\n",
        "# check the test accuracy\n",
        "testpred = NN(augdata, auglabel, test_X)\n",
        "print(\"Accuracy after rotation augmentation:\", Accuracy(test_y, testpred)*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E88Nt9s1p5R6"
      },
      "source": [
        "We can notice a 3-4% improvement compared to non-augmented version of the dataset!\n",
        "\n",
        "The angle constraint is a hyperparameter which we have to tune using a validation set. (Here we are not doing that for time constraints). Let us try a grid search to find the best angle constraint. We will try angles between 0 and 90 degrees. We can also try different multiples of the original dataset. We will use the best hyperparameters to train the model and check the accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiaFRLREmGp6"
      },
      "outputs": [],
      "source": [
        "angleconstraints = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]  # the values we want to test\n",
        "accuracies = np.zeros(\n",
        "    len(angleconstraints), dtype=float\n",
        ")  # we will save the values here\n",
        "\n",
        "for ii in range(len(angleconstraints)):\n",
        "    # create the augmented dataset\n",
        "    augdata = train_X  # we include the original images also in the augmented dataset\n",
        "    auglabel = train_y\n",
        "    for jj in range(naugmentations):\n",
        "        augdata = np.concatenate(\n",
        "            (augdata, augRotate(train_X, angleconstraints[ii]))\n",
        "        )  # concatenate the augmented data to the set\n",
        "        auglabel = np.concatenate(\n",
        "            (auglabel, train_y)\n",
        "        )  # the labels don't change when we augment\n",
        "\n",
        "    # check the test accuracy\n",
        "    testpred = NN(augdata, auglabel, test_X)\n",
        "    accuracies[ii] = Accuracy(test_y, testpred)\n",
        "    print(\n",
        "        \"Accuracy after rotation augmentation constrained by\",\n",
        "        angleconstraints[ii],\n",
        "        \"degrees is\",\n",
        "        accuracies[ii]*100,\n",
        "        \"%\",\n",
        "        flush=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oVDRYP2rxob"
      },
      "source": [
        "Let us see the best value for angle constraint: (Ideally this should be done on validation set, not test set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqthJa_pmMHz"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
        "# plot the variation of accuracy\n",
        "ax.plot(angleconstraints, accuracies)\n",
        "ax.set_xlabel(\"angle\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "\n",
        "# plot the maximum accuracy\n",
        "maxind = np.argmax(accuracies)\n",
        "plt.scatter(angleconstraints[maxind], accuracies[maxind], c=\"red\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ8YuVfCuGTj"
      },
      "source": [
        "### Augmentation 2: Shear\n",
        "\n",
        "\n",
        "Let us try one more augmentation: shear. Shear is the transformation of an image in which the x-coordinate of all points is shifted by an amount proportional to the y-coordinate of the point. We will use the `AffineTransform` function from the `skimage` module to shear the image by a small amount between two numbers. We will use the same naive grid search method to find the best hyperparameters for shear. We will use the best hyperparameters to train the model and check the accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMiw46NLwssK"
      },
      "outputs": [],
      "source": [
        "def shear(sample, amount):\n",
        "    \"\"\"\n",
        "    This function takes in a sample and an amount and returns the augmented sample\n",
        "    by shearing the sample by the given amount\n",
        "\n",
        "    sample: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    amount: the amount by which the sample should be sheared\n",
        "\n",
        "    returns: the augmented sample which is the input sample sheared by the given amount\n",
        "    \"\"\"\n",
        "    tform = AffineTransform(shear=amount)\n",
        "    img = warp(sample, tform)\n",
        "\n",
        "    # Applying shear makes the digit off-center\n",
        "    # Since all images are centralized, we will do the same here\n",
        "    col = img.sum(0).nonzero()[0]\n",
        "    row = img.sum(1).nonzero()[0]\n",
        "    if len(col) > 0 and len(row) > 0:\n",
        "        xshift = int(sample.shape[0] / 2 - (row[0] + row[-1]) / 2)\n",
        "        yshift = int(sample.shape[1] / 2 - (col[0] + col[-1]) / 2)\n",
        "        img = np.roll(img, (xshift, yshift), (0, 1))\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_u_EYpmnABK"
      },
      "outputs": [],
      "source": [
        "sample = train_X[2]\n",
        "fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
        "\n",
        "axs[0].imshow(sample, cmap=\"gray\")\n",
        "axs[0].set_title(\"Original Image\")\n",
        "\n",
        "axs[1].imshow(shear(sample, 0.2), cmap=\"gray\")\n",
        "axs[1].set_title(\"Amount = 0.2\")\n",
        "\n",
        "axs[2].imshow(shear(sample, 0.4), cmap=\"gray\")\n",
        "axs[2].set_title(\"Amount = 0.4\")\n",
        "\n",
        "axs[3].imshow(shear(sample, 0.6), cmap=\"gray\")\n",
        "axs[3].set_title(\"Amount = 0.6\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGnWMoyM2pK4"
      },
      "source": [
        "Create an augmentation function which applies a random shear according to the constraint we provide:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qLDJyGytwP5"
      },
      "outputs": [],
      "source": [
        "def augShear(sample, shearconstraint):\n",
        "    \"\"\"\n",
        "    This function takes in a sample and a shear constraint and returns the augmented sample\n",
        "    by shearing the sample by a random amount within the shear constraint\n",
        "\n",
        "    sample: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    shearconstraint: the maximum shear by which the sample can be sheared\n",
        "\n",
        "    returns: the augmented sample which is the input sample sheared by a random amount within the shear constraint\n",
        "    \"\"\"\n",
        "    if shearconstraint == 0:\n",
        "        return sample\n",
        "    if len(sample.shape) == 2:\n",
        "        # make sure the sample is 3 dimensional\n",
        "        sample = np.expand_dims(sample, 0)\n",
        "    amt = rng.random(len(sample))  # generate random numbers for shear\n",
        "    amt = (amt - 0.5) * shearconstraint  # make the random shear constrained\n",
        "    nsample = sample.copy()  # preallocate the augmented array to make it faster\n",
        "    for ii in range(len(sample)):\n",
        "        nsample[ii] = shear(sample[ii], amt[ii])\n",
        "    return np.squeeze(nsample)  # take care if the input had only one sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6lQcWW93suJ"
      },
      "source": [
        "Let us do a grid search to find the best shear constraint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_wrqPkrzBb_"
      },
      "outputs": [],
      "source": [
        "shearconstraints = [\n",
        "    0,\n",
        "    0.2,\n",
        "    0.4,\n",
        "    0.6,\n",
        "    0.8,\n",
        "    1.0,\n",
        "    1.2,\n",
        "    1.4,\n",
        "    1.6,\n",
        "    1.8,\n",
        "    2.0,\n",
        "]  # the values we want to test\n",
        "accuracies = np.zeros(\n",
        "    len(shearconstraints), dtype=float\n",
        ")  # we will save the values here\n",
        "\n",
        "for ii in range(len(shearconstraints)):\n",
        "    # create the augmented dataset\n",
        "    augdata = train_X  # we include the original images also in the augmented dataset\n",
        "    auglabel = train_y\n",
        "    for jj in range(naugmentations):\n",
        "        augdata = np.concatenate(\n",
        "            (augdata, augShear(train_X, shearconstraints[ii]))\n",
        "        )  # concatenate the augmented data to the set\n",
        "        auglabel = np.concatenate(\n",
        "            (auglabel, train_y)\n",
        "        )  # the labels don't change when we augment\n",
        "\n",
        "    # check the test accuracy\n",
        "    testpred = NN(augdata, auglabel, test_X)\n",
        "    accuracies[ii] = Accuracy(test_y, testpred)\n",
        "    print(\n",
        "        \"Accuracy after shear augmentation constrained by\",\n",
        "        shearconstraints[ii],\n",
        "        \"is\",\n",
        "        accuracies[ii]*100,\n",
        "        \"%\",\n",
        "        flush=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKaH-YR-zVnA"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
        "# plot the variation of accuracy\n",
        "ax.plot(shearconstraints, accuracies)\n",
        "ax.set_xlabel(\"angle\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "\n",
        "# plot the maximum accuracy\n",
        "maxind = np.argmax(accuracies)\n",
        "plt.scatter(shearconstraints[maxind], accuracies[maxind], c=\"red\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccfdbRcQ7Zgg"
      },
      "source": [
        "### Augmentation 3: Rotation + Shear\n",
        "\n",
        "\n",
        "\n",
        "We can do multiple augmentations at the same time. Here is a function to do both shear and rotation to the sample. In this case, we will have two hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh8S_Pxa0XCv"
      },
      "outputs": [],
      "source": [
        "def augRotateShear(sample, angleconstraint, shearconstraint):\n",
        "    \"\"\"\n",
        "    This function takes in a sample, an angle constraint and a shear constraint and returns the augmented sample\n",
        "    by rotating the sample by a random angle within the angle constraint and shearing the sample by a random amount within the shear constraint\n",
        "\n",
        "    sample: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    angleconstraint: the maximum angle by which the sample can be rotated\n",
        "    shearconstraint: the maximum shear by which the sample can be sheared\n",
        "\n",
        "    returns: the augmented sample which is the input sample rotated by a random angle within the angle constraint and sheared by a random amount within the shear constraint\n",
        "    \"\"\"\n",
        "    if len(sample.shape) == 2:\n",
        "        # make sure the sample is 3 dimensional\n",
        "        sample = np.expand_dims(sample, 0)\n",
        "    amt = rng.random(len(sample))  # generate random numbers for shear\n",
        "    amt = (amt - 0.5) * shearconstraint  # make the random shear constrained\n",
        "    angle = rng.random(len(sample))  # generate random numbers for angles\n",
        "    # make the random angle constrained\n",
        "    angle = (angle - 0.5) * angleconstraint\n",
        "    nsample = sample.copy()  # preallocate the augmented array to make it faster\n",
        "    for ii in range(len(sample)):\n",
        "        nsample[ii] = rotate(\n",
        "            shear(sample[ii], amt[ii]), angle[ii]\n",
        "        )  # first apply shear, then rotate\n",
        "    return np.squeeze(nsample)  # take care if the input had only one sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGKyjjNx-NQ4"
      },
      "source": [
        "Since we have two hyperparameters, we have to do the grid search on a 2 dimensional matrix. We can use our previous experience to inform where to search for the best hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJC45WRg0pOP",
        "outputId": "20dcfc35-06a9-43b0-cb74-c84baee17bd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after augmentation shear: 0.0 angle: 0.0 is 63.32 %\n",
            "Accuracy after augmentation shear: 0.0 angle: 10.0 is 63.959999999999994 %\n",
            "Accuracy after augmentation shear: 0.0 angle: 20.0 is 60.64000000000001 %\n",
            "Accuracy after augmentation shear: 0.0 angle: 30.0 is 63.019999999999996 %\n",
            "Accuracy after augmentation shear: 0.0 angle: 40.0 is 64.14999999999999 %\n",
            "Accuracy after augmentation shear: 0.0 angle: 50.0 is 61.72 %\n",
            "Accuracy after augmentation shear: 0.0 angle: 60.0 is 63.7 %\n",
            "Accuracy after augmentation shear: 0.2 angle: 0.0 is 63.41 %\n",
            "Accuracy after augmentation shear: 0.2 angle: 10.0 is 61.25000000000001 %\n",
            "Accuracy after augmentation shear: 0.2 angle: 20.0 is 60.6 %\n",
            "Accuracy after augmentation shear: 0.2 angle: 30.0 is 60.07 %\n",
            "Accuracy after augmentation shear: 0.2 angle: 40.0 is 63.690000000000005 %\n",
            "Accuracy after augmentation shear: 0.2 angle: 50.0 is 60.12 %\n",
            "Accuracy after augmentation shear: 0.2 angle: 60.0 is 63.72 %\n",
            "Accuracy after augmentation shear: 0.4 angle: 0.0 is 63.370000000000005 %\n",
            "Accuracy after augmentation shear: 0.4 angle: 10.0 is 63.480000000000004 %\n",
            "Accuracy after augmentation shear: 0.4 angle: 20.0 is 62.6 %\n",
            "Accuracy after augmentation shear: 0.4 angle: 30.0 is 59.099999999999994 %\n",
            "Accuracy after augmentation shear: 0.4 angle: 40.0 is 62.81 %\n",
            "Accuracy after augmentation shear: 0.4 angle: 50.0 is 60.49 %\n",
            "Accuracy after augmentation shear: 0.4 angle: 60.0 is 62.57 %\n",
            "Accuracy after augmentation shear: 0.6 angle: 0.0 is 63.3 %\n",
            "Accuracy after augmentation shear: 0.6 angle: 10.0 is 60.440000000000005 %\n",
            "Accuracy after augmentation shear: 0.6 angle: 20.0 is 63.349999999999994 %\n",
            "Accuracy after augmentation shear: 0.6 angle: 30.0 is 60.9 %\n",
            "Accuracy after augmentation shear: 0.6 angle: 40.0 is 62.68 %\n",
            "Accuracy after augmentation shear: 0.6 angle: 50.0 is 62.17 %\n",
            "Accuracy after augmentation shear: 0.6 angle: 60.0 is 63.24999999999999 %\n",
            "Accuracy after augmentation shear: 0.8 angle: 0.0 is 63.4 %\n",
            "Accuracy after augmentation shear: 0.8 angle: 10.0 is 62.19 %\n",
            "Accuracy after augmentation shear: 0.8 angle: 20.0 is 61.67 %\n",
            "Accuracy after augmentation shear: 0.8 angle: 30.0 is 61.83 %\n",
            "Accuracy after augmentation shear: 0.8 angle: 40.0 is 61.11 %\n",
            "Accuracy after augmentation shear: 0.8 angle: 50.0 is 61.8 %\n",
            "Accuracy after augmentation shear: 0.8 angle: 60.0 is 63.06 %\n",
            "Accuracy after augmentation shear: 1.0 angle: 0.0 is 63.36000000000001 %\n",
            "Accuracy after augmentation shear: 1.0 angle: 10.0 is 59.84 %\n",
            "Accuracy after augmentation shear: 1.0 angle: 20.0 is 64.03 %\n",
            "Accuracy after augmentation shear: 1.0 angle: 30.0 is 61.92999999999999 %\n",
            "Accuracy after augmentation shear: 1.0 angle: 40.0 is 62.760000000000005 %\n",
            "Accuracy after augmentation shear: 1.0 angle: 50.0 is 62.419999999999995 %\n",
            "Accuracy after augmentation shear: 1.0 angle: 60.0 is 61.919999999999995 %\n",
            "Accuracy after augmentation shear: 1.2 angle: 0.0 is 63.480000000000004 %\n",
            "Accuracy after augmentation shear: 1.2 angle: 10.0 is 59.660000000000004 %\n",
            "Accuracy after augmentation shear: 1.2 angle: 20.0 is 63.07000000000001 %\n",
            "Accuracy after augmentation shear: 1.2 angle: 30.0 is 64.28 %\n",
            "Accuracy after augmentation shear: 1.2 angle: 40.0 is 62.3 %\n",
            "Accuracy after augmentation shear: 1.2 angle: 50.0 is 63.36000000000001 %\n",
            "Accuracy after augmentation shear: 1.2 angle: 60.0 is 61.529999999999994 %\n",
            "Accuracy after augmentation shear: 1.4 angle: 0.0 is 63.57000000000001 %\n",
            "Accuracy after augmentation shear: 1.4 angle: 10.0 is 63.0 %\n",
            "Accuracy after augmentation shear: 1.4 angle: 20.0 is 62.55 %\n",
            "Accuracy after augmentation shear: 1.4 angle: 30.0 is 60.68 %\n",
            "Accuracy after augmentation shear: 1.4 angle: 40.0 is 62.81 %\n",
            "Accuracy after augmentation shear: 1.4 angle: 50.0 is 61.23 %\n",
            "Accuracy after augmentation shear: 1.4 angle: 60.0 is 63.22 %\n",
            "Accuracy after augmentation shear: 1.6 angle: 0.0 is 63.32 %\n",
            "Accuracy after augmentation shear: 1.6 angle: 10.0 is 60.709999999999994 %\n",
            "Accuracy after augmentation shear: 1.6 angle: 20.0 is 62.61 %\n",
            "Accuracy after augmentation shear: 1.6 angle: 30.0 is 59.699999999999996 %\n",
            "Accuracy after augmentation shear: 1.6 angle: 40.0 is 64.21 %\n"
          ]
        }
      ],
      "source": [
        "shearconstraints = [\n",
        "    0,\n",
        "    0.2,\n",
        "    0.4,\n",
        "    0.6,\n",
        "    0.8,\n",
        "    1.0,\n",
        "    1.2,\n",
        "    1.4,\n",
        "    1.6,\n",
        "]  # the values we want to test\n",
        "angleconstraints = [0, 10, 20, 30, 40, 50, 60]  # the values we want to test\n",
        "# cartesian product of both\n",
        "hyp = cartesian((shearconstraints, angleconstraints))\n",
        "\n",
        "accuracies = np.zeros(len(hyp), dtype=float)  # we will save the values here\n",
        "\n",
        "for ii in range(len(hyp)):\n",
        "    # create the augmented dataset\n",
        "    augdata = train_X  # we include the original images also in the augmented dataset\n",
        "    auglabel = train_y\n",
        "    for jj in range(naugmentations):\n",
        "        augdata = np.concatenate(\n",
        "            (augdata, augRotateShear(train_X, hyp[ii][0], hyp[ii][1]))\n",
        "        )  # concatenate the augmented data to the set\n",
        "        auglabel = np.concatenate(\n",
        "            (auglabel, train_y)\n",
        "        )  # the labels don't change when we augment\n",
        "\n",
        "    # check the test accuracy\n",
        "    testpred = NN(augdata, auglabel, test_X)\n",
        "    accuracies[ii] = Accuracy(test_y, testpred)\n",
        "    print(\n",
        "        \"Accuracy after augmentation shear:\",\n",
        "        hyp[ii][0],\n",
        "        \"angle:\",\n",
        "        hyp[ii][1],\n",
        "        \"is\",\n",
        "        accuracies[ii]*100,\n",
        "        \"%\",\n",
        "        flush=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT6CnvSDEX7a"
      },
      "source": [
        "Let us plot it two dimensionally to see which is the best value for the hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jD2i7msI_cLd"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
        "im = ax.imshow(\n",
        "    accuracies.reshape((len(shearconstraints), len(angleconstraints))), cmap=\"hot\"\n",
        ")\n",
        "ax.set_xlabel(\"Angle\")\n",
        "ax.set_ylabel(\"Shear\")\n",
        "ax.set_xticks(np.arange(len(angleconstraints)))\n",
        "ax.set_xticklabels(angleconstraints)\n",
        "ax.set_yticks(np.arange(len(shearconstraints)))\n",
        "ax.set_yticklabels(shearconstraints)\n",
        "plt.colorbar(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHcZWJiFJDMh"
      },
      "source": [
        "It seems that rotation and shear don't mix! The best accuracy is when rotation is zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAasQo1C3x4A"
      },
      "source": [
        "## Questions\n",
        "Try these questions for better understanding. You may not be able to solve all of them.\n",
        "1. What is the best value for angle constraint and shear constraint you got? How much did the accuracy improve as compared to not using augmentations?\n",
        "2. Can you increase the accuracy by increasing the number of augmentations from each sample?\n",
        "3. Try implementing a few augmentations of your own and experimenting with them. A good reference is <a href=https://www.analyticsvidhya.com/blog/2019/12/image-augmentation-deep-learning-pytorch/>here. </a>\n",
        "4. Try combining various augmentations. What is the highest accuracy you can get? What is the smallest training dataset you can take and still get accuracy above 50%?\n",
        "\n",
        "Whenever you do any experiment, a good practice is to vary the hyperparameters gradually and create a graph of your results, like we did for gridsearch."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1AnsCould you clarify the specific problem or dataset you're referring to, as well as the model you're working with? This will help me give you more targeted insights regarding the best values for angle and shear constraints, and how augmentation affected your model's accuracy.\n",
        "\n",
        "If you're referring to a general case in computer vision, here's a breakdown of how angle (rotation) and shear constraints in data augmentation can influence performance:\n",
        "\n",
        "1. Angle Constraint (Rotation)\n",
        "\n",
        "This refers to the degree of rotation applied to images during augmentation. Small rotations (typically between -15° to 15°) tend to work well for most tasks because they introduce variability without distorting the object in the image.\n",
        "\n",
        "If the dataset contains objects that appear in various orientations, a wider range of angles might be appropriate (e.g., -30° to 30° or even -45° to 45°).\n",
        "\n",
        "Effect on Accuracy: Rotation often improves accuracy by making the model more robust to different orientations. However, too much rotation can lead to distorted images and hurt performance. In general, modest improvements of 2-5% in validation/test accuracy are common with well-tuned rotations.\n",
        "\n",
        "\n",
        "2. Shear Constraint\n",
        "\n",
        "Shear refers to slanting the image, where one axis is stretched more than the other. Common values for shear range between 0.1 and 0.3 (or equivalently, 10° to 30° shear), depending on how much distortion your model can handle.\n",
        "\n",
        "Shear augmentations are helpful when objects in the dataset are viewed from varying angles or perspectives.\n",
        "\n",
        "Effect on Accuracy: Shear can improve performance by making the model invariant to perspective distortions, though it is less commonly used than rotation. It tends to contribute to small improvements (1-3%) in accuracy if the dataset benefits from perspective changes.\n",
        "\n",
        "\n",
        "Comparison to No Augmentations\n",
        "\n",
        "Typically, applying augmentations such as rotation and shear can lead to accuracy improvements of 5-10% depending on the dataset and model architecture. The improvement is more pronounced in small datasets or when the dataset has a lot of variability in object orientation or perspective.\n",
        "\n",
        "Without augmentations, the model may overfit to the training data because it sees only a limited set of variations. With augmentations, the model becomes more robust and generalizes better to unseen data, leading to higher accuracy on the test set.\n",
        "\n",
        "\n",
        "Key Considerations:\n",
        "\n",
        "Dataset Type: The effectiveness of these augmentations depends heavily on the dataset. For example, in digit recognition tasks (like MNIST), small rotations and shear transformations often improve accuracy. In contrast, for tasks where object orientation is fixed (e.g., face recognition), too much rotation or shear may degrade performance.\n",
        "\n",
        "Model Capacity: Augmentations tend to benefit deep models more, as they have the capacity to learn from the additional variability introduced by augmentations.\n",
        "\n",
        "\n",
        "If you provide more details, I can give you a more specific recommendation."
      ],
      "metadata": {
        "id": "bvnGwRYOSTY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2AnsYes, increasing the number of augmentations from each sample can improve accuracy, but the extent of improvement depends on several factors, such as the dataset size, task complexity, and model capacity. Here's how and why generating more augmentations from each sample can impact performance:\n",
        "\n",
        "1. Increasing Dataset Variability\n",
        "\n",
        "By generating multiple augmentations from each sample, you're artificially increasing the size of your dataset, which introduces more variability for the model to learn from. This helps prevent overfitting, especially when the original dataset is small or lacks diversity.\n",
        "\n",
        "The model sees more diverse examples of the data, which can improve its ability to generalize to unseen samples.\n",
        "\n",
        "\n",
        "2. Improved Generalization\n",
        "\n",
        "With more augmentations, the model learns to be invariant to transformations such as rotations, flips, or color changes. This makes the model more robust to variations in real-world data, improving test accuracy.\n",
        "\n",
        "For example, in tasks like image classification, augmenting each sample with multiple versions (e.g., rotated, sheared, cropped, etc.) can make the model less sensitive to irrelevant features like orientation or lighting.\n",
        "\n",
        "\n",
        "3. Diminishing Returns\n",
        "\n",
        "While more augmentations generally help, there are diminishing returns after a certain point. If too many augmentations are applied, the model might start to learn noise or unrealistic features that do not exist in real-world data.\n",
        "\n",
        "At some point, the additional augmentations may no longer provide meaningful new information, and the computational cost increases without a proportional gain in accuracy.\n",
        "\n",
        "\n",
        "4. Over-Augmentation Risks\n",
        "\n",
        "If too many or overly aggressive augmentations are applied (e.g., excessive rotations, shear, or noise), the data might become distorted to the point where it no longer represents the true distribution. This can confuse the model and lead to worse performance.\n",
        "\n",
        "It’s important to balance the number and type of augmentations so that they still reflect real-world variations.\n",
        "\n",
        "\n",
        "5. Impact on Small vs. Large Datasets\n",
        "\n",
        "Small Datasets: When the training data is limited, augmenting each sample multiple times can significantly improve model performance by acting as a form of regularization and reducing overfitting. The model becomes more exposed to variations, which it wouldn't have otherwise seen in a small dataset.\n",
        "\n",
        "Large Datasets: For large datasets, the effect of augmenting each sample multiple times may be less pronounced since the dataset already contains substantial variability. In such cases, moderate augmentation may be enough to achieve good results, and further augmentations might not provide significant improvements.\n",
        "\n",
        "\n",
        "Practical Considerations\n",
        "\n",
        "1. Balanced Augmentations: Focus on realistic augmentations that represent the types of variability your model might encounter in the real world. For example, if you're building a model to recognize objects in photos, augmentations like random rotations, cropping, or lighting changes are appropriate. Overly extreme transformations may hurt performance.\n",
        "\n",
        "\n",
        "2. Data Augmentation with Deep Learning: Deep models can handle a lot of data and benefit more from large amounts of augmentations, but shallow models may not leverage this increased variability as effectively. Make sure your model architecture is sufficiently complex to learn from the augmented data.\n",
        "\n",
        "\n",
        "3. Use of Online Augmentation: Instead of generating and storing multiple augmentations per sample upfront (which could be memory-intensive), you can apply augmentations on-the-fly during training. This creates effectively infinite variations of the data without increasing storage requirements.\n",
        "\n",
        "\n",
        "4. Fine-Tuning: You can first train your model without augmentations or with minimal augmentations, then progressively increase the number of augmentations in later stages of training. This can sometimes help stabilize learning.\n",
        "\n",
        "\n",
        "\n",
        "Example of Augmentation Benefits\n",
        "\n",
        "CIFAR-10 and ImageNet: In benchmark datasets like CIFAR-10 and ImageNet, data augmentation (especially random crops, horizontal flips, and color jittering) has been shown to significantly boost accuracy. Some models see an improvement of 2-5% just from augmenting each sample in different ways.\n",
        "\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Increasing the number of augmentations from each sample generally improves accuracy, particularly for small or medium-sized datasets, by introducing more data variability and improving generalization. However, the improvement has diminishing returns beyond a certain point, and overly aggressive augmentations can actually harm model performance. The key is to strike the right balance between the quantity and quality of augmentations, ensuring they reflect real-world variations."
      ],
      "metadata": {
        "id": "DwWQRS4eTZ_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3AnsIt seems you mentioned a reference, but I don’t have access to external resources directly. However, I can still help you implement common augmentations and suggest a process for experimenting with them.\n",
        "\n",
        "Here’s a basic guide for implementing augmentations in popular machine learning libraries like TensorFlow/Keras or PyTorch, followed by some ideas on how to experiment with them.\n",
        "\n",
        "Step 1: Implementing Common Augmentations\n",
        "\n",
        "You can use a variety of augmentations such as rotations, flips, shear transformations, and brightness adjustments to make your dataset more diverse.\n",
        "\n",
        "1. In TensorFlow/Keras:\n",
        "\n",
        "Keras has a built-in ImageDataGenerator for augmentations, or you can use tf.image for more customized augmentations.\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an ImageDataGenerator instance\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,         # Random rotations between -30 and 30 degrees\n",
        "    width_shift_range=0.2,     # Random horizontal shifts\n",
        "    height_shift_range=0.2,    # Random vertical shifts\n",
        "    shear_range=0.2,           # Shear transformations\n",
        "    zoom_range=0.2,            # Zooming in/out\n",
        "    horizontal_flip=True,      # Random horizontal flips\n",
        "    fill_mode='nearest'        # Filling empty space with nearest pixels\n",
        ")\n",
        "\n",
        "# Applying augmentations to training data\n",
        "train_datagen = datagen.flow_from_directory('train_data_path', target_size=(150, 150), batch_size=32)\n",
        "\n",
        "You can also use tf.image for custom augmentations:\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def augment(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
        "    image = tf.image.random_rotation(image, angles=0.2)\n",
        "    return image\n",
        "\n",
        "# Apply augmentations to dataset\n",
        "dataset = dataset.map(lambda x, y: (augment(x), y))\n",
        "\n",
        "2. In PyTorch:\n",
        "\n",
        "PyTorch provides torchvision.transforms for augmentations:\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define augmentations\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(30),  # Random rotations\n",
        "    transforms.RandomResizedCrop(224),  # Random cropping and resizing\n",
        "    transforms.RandomHorizontalFlip(),  # Random horizontal flips\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Adjust brightness, contrast\n",
        "    transforms.ToTensor(),  # Convert image to tensor\n",
        "])\n",
        "\n",
        "# Apply augmentations\n",
        "train_dataset = torchvision.datasets.ImageFolder('train_data_path', transform=train_transforms)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "Step 2: Experimenting with Augmentations\n",
        "\n",
        "To experiment with augmentations and observe their effects on accuracy, you can try varying the following:\n",
        "\n",
        "1. Type of Augmentation:\n",
        "\n",
        "Rotation: Experiment with rotation angles, from small rotations (±15°) to larger ones (±45°).\n",
        "\n",
        "Flips: Use horizontal or vertical flips (depending on whether they make sense for your data).\n",
        "\n",
        "Shear Transformations: Experiment with shearing in different directions and magnitudes.\n",
        "\n",
        "Brightness, Contrast, and Saturation: Vary these to simulate different lighting conditions.\n",
        "\n",
        "\n",
        "2. Number of Augmentations per Sample:\n",
        "\n",
        "Generate multiple augmentations for each sample and compare performance. For example, for each image, you could apply 2–3 augmentations (rotation + flip + brightness adjustment) and then compare it to only applying one augmentation.\n",
        "\n",
        "\n",
        "3. Intensity of Augmentations:\n",
        "\n",
        "Try different ranges for augmentations (e.g., larger vs. smaller rotations or shears). This can help determine if the model performs better with subtle or more aggressive changes.\n",
        "\n",
        "\n",
        "4. Without Augmentations vs. Augmentations:\n",
        "\n",
        "Compare model performance with and without augmentations to quantify the effect of data augmentation. Start with no augmentations, then progressively add different augmentations to see how much the accuracy improves.\n",
        "\n",
        "\n",
        "Step 3: Evaluating Performance\n",
        "\n",
        "Track performance metrics such as accuracy and loss on the validation and test sets. You can log the performance after each experiment and visualize the improvements (or drop) in accuracy as you change the types and amounts of augmentations.\n",
        "\n",
        "Example Process:\n",
        "\n",
        "1. Baseline (No Augmentation):\n",
        "\n",
        "Train the model without any augmentations to establish a baseline accuracy.\n",
        "\n",
        "\n",
        "\n",
        "2. Adding One Augmentation at a Time:\n",
        "\n",
        "Apply simple augmentations (e.g., random horizontal flips) and train the model again.\n",
        "\n",
        "Observe how accuracy changes compared to the baseline.\n",
        "\n",
        "\n",
        "\n",
        "3. Combining Multiple Augmentations:\n",
        "\n",
        "Apply multiple augmentations (e.g., rotation + shear + brightness) and train.\n",
        "\n",
        "Compare performance to both the baseline and the single-augmentation setup.\n",
        "\n",
        "\n",
        "\n",
        "4. Vary Augmentation Intensity:\n",
        "\n",
        "Increase or decrease the intensity of the augmentations (e.g., try smaller/larger rotations or contrast adjustments).\n",
        "\n",
        "Record how this impacts validation and test accuracy.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "If you have a specific reference or target model/dataset in mind, I can help you tailor the augmentation experiments further."
      ],
      "metadata": {
        "id": "RWpWcA1gT1rt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4AnsTo conduct the experiments of combining various augmentations and testing their impact on accuracy, as well as determining the smallest dataset that yields an accuracy above 50%, the following steps would be involved:\n",
        "\n",
        "1. Combining Various Augmentations:\n",
        "\n",
        "We’ll combine augmentations such as:\n",
        "\n",
        "Rotation: Introduces random rotations to images.\n",
        "\n",
        "Shear: Applies affine transformations to images.\n",
        "\n",
        "Horizontal Flip: Randomly flips images horizontally.\n",
        "\n",
        "Brightness, Contrast Adjustments: Simulate lighting conditions.\n",
        "\n",
        "Zoom/Crop: Randomly zoom in or crop regions of the image.\n",
        "\n",
        "\n",
        "For illustration purposes, let’s assume we're working with a dataset like CIFAR-10 (or any image classification dataset). You could run this experiment in TensorFlow/Keras or PyTorch.\n",
        "\n",
        "Experiment Setup in TensorFlow/Keras:\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Load and preprocess CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
        "\n",
        "# Define augmentations\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Define a simple CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train with data augmentation\n",
        "batch_size = 64\n",
        "epochs = 50  # Can be adjusted\n",
        "train_generator = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
        "model.fit(train_generator, epochs=epochs, validation_data=(x_test, y_test))\n",
        "\n",
        "This code will apply multiple augmentations and train a CNN on CIFAR-10. After training, you would get a test accuracy and could log it for comparison.\n",
        "\n",
        "2. Testing on Smaller Training Dataset:\n",
        "\n",
        "To determine the smallest dataset size that still achieves more than 50% accuracy, you can progressively reduce the size of the training dataset and retrain the model. Here's how to sample smaller datasets:\n",
        "\n",
        "# Reduce the dataset size\n",
        "small_train_size = 1000  # Starting with 1000 samples for training\n",
        "x_small_train = x_train[:small_train_size]\n",
        "y_small_train = y_train[:small_train_size]\n",
        "\n",
        "# Train on smaller dataset with augmentations\n",
        "train_generator_small = datagen.flow(x_small_train, y_small_train, batch_size=batch_size)\n",
        "model.fit(train_generator_small, epochs=epochs, validation_data=(x_test, y_test))\n",
        "\n",
        "You can gradually reduce the size of the training set (e.g., 500, 250, etc.) and retrain to see the point where the accuracy drops below 50%. Track how the augmentations compensate for the small dataset size.\n",
        "\n",
        "Key Points:\n",
        "\n",
        "1. Experiment with Data Size:\n",
        "\n",
        "Start with 1000 training samples and progressively decrease the size. Use the augmentation pipeline to make the model more robust despite the small dataset size.\n",
        "\n",
        "After each experiment, evaluate the model's accuracy and check whether it remains above 50%.\n",
        "\n",
        "\n",
        "\n",
        "2. Combining Augmentations:\n",
        "\n",
        "Experiment with different combinations of augmentations and measure their effect on validation accuracy.\n",
        "\n",
        "Common combinations include rotation + flip + shear or zoom + crop + contrast.\n",
        "\n",
        "\n",
        "\n",
        "3. Stopping Criteria:\n",
        "\n",
        "When the model accuracy drops below 50%, note the corresponding dataset size.\n",
        "\n",
        "You may find that with a well-chosen augmentation strategy, the model can perform surprisingly well on small datasets.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Expected Outcomes:\n",
        "\n",
        "With Augmentations: You might achieve an accuracy of 50-70% even with a reduced dataset (e.g., 500-1000 samples) if the augmentations are varied and realistic.\n",
        "\n",
        "Without Augmentations: On"
      ],
      "metadata": {
        "id": "k7B6_LtuUNre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Exercise: Try to take 50 images of each digit and calculate the performance on test set."
      ],
      "metadata": {
        "id": "zu590B33-Xp_"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}